<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <title>Parallel programming with MPI, part II</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="/home/jtonttil/SOFTWARE/slidefactory/lib/slidefactory/reveal.js/css/reveal.css">
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="/home/jtonttil/SOFTWARE/slidefactory/lib/slidefactory/theme/csc-2016/csc.css" id="theme">
  <link rel="stylesheet" href="/home/jtonttil/SOFTWARE/slidefactory/lib/slidefactory/theme/csc-2016/fonts.css">
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? '/home/jtonttil/SOFTWARE/slidefactory/lib/slidefactory/reveal.js/css/print/pdf.css' : '/home/jtonttil/SOFTWARE/slidefactory/lib/slidefactory/reveal.js/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="/home/jtonttil/SOFTWARE/slidefactory/lib/slidefactory/reveal.js/lib/js/html5shiv.js"></script>
  <![endif]-->
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section class="slide level1 title" data-background-size="contain" data-background-image="/home/jtonttil/SOFTWARE/slidefactory/lib/slidefactory/theme/csc-2016/img/title-en.png">
  <h1>Parallel programming with MPI, part II</h1>
  <p>ESiWACE3-WarmWorld Summer School on HPC for Climate and Weather Applications</p>
</section>

<section id="learning-objectives-part-ii" class="slide level1" data-background-size="contain">
<h1>Learning objectives, part II</h1>
<ul>
<li><p>Understand the non-blocking communication concept</p></li>
<li><p>Understand the collective communication concept</p></li>
<li><p>Know how to implement basic parallel arithmetics using the collective functions</p></li>
</ul>
</section>
<section id="non-blocking-point-to-point-communication" class="slide level1 section" data-background-size="contain" data-background-image="/home/jtonttil/SOFTWARE/slidefactory/lib/slidefactory/theme/csc-2016/img/section.png">
<h1>Non-blocking point-to-point communication</h1>
</section>
<section id="non-blocking-communication" class="slide level1" data-background-size="contain">
<h1>Non-blocking communication</h1>
<ul>
<li>Functions return immediately → continue program execution with concurrent operations</li>
<li>Must check explicitly the communication has completed by the time the data is needed
<ul>
<li>Blocking: <strong><code>MPI_Wait</code></strong>,<strong><code>MPI_Waitall</code></strong></li>
<li>Non-blocking <strong><code>MPI_Test</code></strong> ← require periodical testing</li>
</ul></li>
</ul>
</section>
<section id="non-blocking-send" class="slide level1 split-definition" data-background-size="contain">
<h1>Non-blocking Send</h1>
<ul>
<li>Same parameters as with regular <strong><code>MPI_Send</code></strong> plus <strong><code>request</code></strong></li>
</ul>
<dl>
<dt>MPI_ISend(<code class="input">buf</code>, <code class="input">count</code>, <code class="input">datatype</code>, <code class="input">dest</code>, <code class="input">tag</code>, <code class="input">comm</code>, <code class="output">request</code>, <code class="output">err</code>)</dt>
<dd><dl>
<dt>type(*) <code class="input">buf(..)</code></dt>
<dd>Send buffer that must not be written to until one has checked that the operation is over
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="output">request</code></dt>
<dd>A handle used to check if communication has finished
</dd>
</dl>
</dd>
</dl>
</section>
<section id="non-blocking-recv" class="slide level1 split-definition" data-background-size="contain">
<h1>Non-blocking Recv</h1>
<ul>
<li>Same as with regular <strong><code>MPI_Recv</code></strong> plus <strong><code>request</code></strong>, without <strong><code>status</code></strong></li>
</ul>
<dl>
<dt>MPI_IRecv(<code class="output">buf</code>, <code class="input">count</code>, <code class="input">datatype</code>, <code class="input">source</code>, <code class="input">tag</code>, <code class="input">comm</code>, <code class="output">request</code>, <code class="output">err</code>)</dt>
<dd><dl>
<dt>type(*) <code class="output">buf(..)</code></dt>
<dd>Receive buffer guaranteed to contain the data only after one has checked that the operation is over
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="output">request</code></dt>
<dd>A handle used to check if communication has finished
</dd>
</dl>
</dd>
</dl>
</section>
<section id="finalizing-non-blocking-communication" class="slide level1 split-definition" data-background-size="contain">
<h1>Finalizing non-blocking communication</h1>
<dl>
<dt>MPI_Wait(<code class="input">request</code>, <code class="output">status</code>, <code class="output">err</code>)</dt>
<dd><dl>
<dt>type(MPI_Request) <code class="input">request</code></dt>
<dd>Handle of the non-blocking communication
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="output">status(MPI_STATUS_SIZE)</code></dt>
<dd>Status of the completed communication, same as in <strong><code>MPI_Recv</code></strong>
</dd>
</dl>
</dd>
<dt>MPI_Waitall(<code class="input">count</code>, <code class="input">requests</code>, <code class="output">status</code>, <code class="output">err</code>)</dt>
<dd><dl>
<dt>integer <code class="input">count</code></dt>
<dd>Number of requests
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">requests(count)</code></dt>
<dd>Array of requests
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="output">status(MPI_STATUS_SIZE,*)</code></dt>
<dd>Array of statuses
</dd>
</dl>
</dd>
</dl>
</section>
<section id="finalizing-non-blocking-communication-1" class="slide level1 split-definition" data-background-size="contain">
<h1>Finalizing non-blocking communication</h1>
<dl>
<dt>MPI_Test(<code class="input">request</code>, <code class="output">flag</code>, <code class="output">status</code>, <code class="output">err</code>)</dt>
<dd><dl>
<dt>integer <code class="input">request</code></dt>
<dd>Request
</dd>
</dl>
</dd>
<dd><dl>
<dt>logical <code class="output">flag</code></dt>
<dd>True if the operation has completed
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="output">status(MPI_STATUS_SIZE)</code></dt>
<dd>Status for the completed operation
</dd>
</dl>
</dd>
</dl>
<p><br></p>
<ul>
<li>A call to <strong><code>MPI_Test</code></strong> is non-blocking. It allows one to schedule alternative activities while periodically checking for completion.</li>
</ul>
</section>
<section id="collective-communication" class="slide level1 section" data-background-size="contain" data-background-image="/home/jtonttil/SOFTWARE/slidefactory/lib/slidefactory/theme/csc-2016/img/section.png">
<h1>Collective communication</h1>
</section>
<section id="collective-communication-1" class="slide level1" data-background-size="contain">
<h1>Collective communication</h1>
<ul>
<li>Transmit data among all the processes in a communicator
<ul>
<li>Easier to implement and understand, and often more efficient that building same functionality with point-to-point communications</li>
</ul></li>
<li><p><strong>Must</strong> be called by all processes, i.e. no rank based branching</p></li>
<li>Various types
<ul>
<li>Data distribution</li>
<li>Collective computation – reduction operations</li>
<li>Synchronization</li>
</ul></li>
</ul>
</section>
<section id="mpi_bcast" class="slide level1" data-background-size="contain">
<h1><strong><code>MPI_Bcast</code></strong></h1>
<ul>
<li>Send a buffer from a root process to all other processes</li>
</ul>
<p><img data-src="img/bcast.svg" class="center" style="width:40.0%" /></p>
</section>
<section id="mpi_bcast-1" class="slide level1 split-definition" data-background-size="contain">
<h1><strong><code>MPI_Bcast</code></strong></h1>
<dl>
<dt>MPI_Bcast(<code class="input">buf</code><code class="output">fer</code>, <code class="input">count</code>, <code class="input">datatype</code>, <code class="input">root</code>, <code class="input">comm</code>, <code class="output">err</code>)</dt>
<dd><dl>
<dt>type(*) <code class="input">buf</code><code class="output">fer(..)</code></dt>
<dd>Data to be broadcasted / received
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">count</code></dt>
<dd>Number of elements in buffer
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">datatype</code></dt>
<dd>Type of elements in buffer
</dd>
</dl>
</dd>
<dd><p>integer <code class="input">root</code></p>
</dd>
<dd><dl>
<dt>type(*) <code class="input">buf</code><code class="output">fer(..)</code></dt>
<dd>Data to be broadcasted / received
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">count</code></dt>
<dd>Number of elements in buffer
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">datatype</code></dt>
<dd>Type of elements in buffer
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">root</code></dt>
<dd>The rank of sending process
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">comm</code></dt>
<dd>Communicator
</dd>
</dl>
</dd>
</dl>
</section>
<section id="mpi_scatter" class="slide level1 split-definition" data-background-size="contain">
<h1><strong><code>MPI_Scatter</code></strong></h1>
<ul>
<li>Spread data evenly from a root process to all other processes</li>
</ul>
<p><img data-src="img/scatter.svg" class="center" style="width:60.0%" /></p>
</section>
<section id="mpi_scatter-1" class="slide level1 split-definition" data-background-size="contain">
<h1><strong><code>MPI_Scatter</code></strong></h1>
<dl>
<dt>MPI_Scatter(<code class="input">sendbuf</code>, <code class="input">sendcount</code>, <code class="input">sendtype</code>, <code class="output">recvbuf</code>, <code class="input">recvcount</code>, <code class="input">recvtype</code>, <code class="input">root</code>, <code class="input">comm</code>, <code class="output">err</code>)</dt>
<dd><dl>
<dt>type(*) <code class="input">sendbuf(..)</code></dt>
<dd>Data to be scattered
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">sendcount</code></dt>
<dd>Number of elements to send to each process
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">sendtype</code></dt>
<dd>Type of elements in send buffer
</dd>
</dl>
</dd>
<dd><dl>
<dt>type(*) <code class="output">recvbuf(..)</code></dt>
<dd>Buffer for receiving data
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">recvcount</code></dt>
<dd>Number of elements to receive
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">recvtype</code></dt>
<dd>Type of elements to receive
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">root</code></dt>
<dd>The rank of sending process
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">comm</code></dt>
<dd>Communicator
</dd>
</dl>
</dd>
</dl>
</section>
<section id="mpi_scatter-example" class="slide level1 split-definition" data-background-size="contain">
<h1><strong><code>MPI_Scatter</code></strong> example</h1>
<div class="column">
<ul>
<li>For 4 MPI processes</li>
</ul>
<div class="sourceCode" id="cb1"><pre class="sourceCode fortran"><code class="sourceCode fortran"><a class="sourceLine" id="cb1-1" title="1"><span class="kw">IF</span> (rank<span class="op">==</span><span class="dv">0</span>) <span class="kw">THEN</span></a>
<a class="sourceLine" id="cb1-2" title="2">    <span class="kw">DO</span> i <span class="kw">=</span> <span class="dv">1</span>, <span class="dv">16</span></a>
<a class="sourceLine" id="cb1-3" title="3">        a(i) <span class="kw">=</span> i</a>
<a class="sourceLine" id="cb1-4" title="4">    <span class="kw">END DO</span></a>
<a class="sourceLine" id="cb1-5" title="5"><span class="kw">END IF</span></a>
<a class="sourceLine" id="cb1-6" title="6"><span class="kw">CALL</span> MPI_Scatter(a, <span class="dv">4</span>, MPI_<span class="dt">INTEGER</span>, aloc, <span class="dv">4</span> <span class="kw">&amp;</span></a>
<a class="sourceLine" id="cb1-7" title="7">              MPI_<span class="dt">INTEGER</span>, <span class="dv">0</span>, MPI_COMM_WORLD, <span class="kw">&amp;</span></a>
<a class="sourceLine" id="cb1-8" title="8">              err)</a>
<a class="sourceLine" id="cb1-9" title="9"><span class="kw">IF</span> (rank<span class="op">==</span><span class="dv">2</span>) <span class="fu">WRITE(*</span>,<span class="fu">*)</span> aloc(:)</a></code></pre></div>
</div>
<div class="column">
<p>What would be the result?</p>
</div>
</section>
<section id="mpi_scatter-example-1" class="slide level1 split-definition" data-background-size="contain">
<h1><strong><code>MPI_Scatter</code></strong> example</h1>
<div class="column">
<ul>
<li>For 4 MPI processes</li>
</ul>
<div class="sourceCode" id="cb2"><pre class="sourceCode fortran"><code class="sourceCode fortran"><a class="sourceLine" id="cb2-1" title="1"><span class="kw">IF</span> (rank<span class="op">==</span><span class="dv">0</span>) <span class="kw">THEN</span></a>
<a class="sourceLine" id="cb2-2" title="2">    <span class="kw">DO</span> i <span class="kw">=</span> <span class="dv">1</span>, <span class="dv">16</span></a>
<a class="sourceLine" id="cb2-3" title="3">        a(i) <span class="kw">=</span> i</a>
<a class="sourceLine" id="cb2-4" title="4">    <span class="kw">END DO</span></a>
<a class="sourceLine" id="cb2-5" title="5"><span class="kw">END IF</span></a>
<a class="sourceLine" id="cb2-6" title="6"><span class="kw">CALL</span> MPI_Scatter(a, <span class="dv">4</span>, MPI_<span class="dt">INTEGER</span>, aloc, <span class="dv">4</span> <span class="kw">&amp;</span></a>
<a class="sourceLine" id="cb2-7" title="7">              MPI_<span class="dt">INTEGER</span>, <span class="dv">0</span>, MPI_COMM_WORLD, <span class="kw">&amp;</span></a>
<a class="sourceLine" id="cb2-8" title="8">              err)</a>
<a class="sourceLine" id="cb2-9" title="9"><span class="kw">IF</span> (rank<span class="op">==</span><span class="dv">2</span>) <span class="fu">WRITE(*</span>,<span class="fu">*)</span> aloc(:)</a></code></pre></div>
</div>
<div class="column">
<p>What would be the result?</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb3-1" title="1"><span class="ex">9</span> 10 11 12</a></code></pre></div>
</div>
</section>
<section id="mpi_scatter-example-2" class="slide level1 split-definition" data-background-size="contain">
<h1><strong><code>MPI_Scatter</code></strong> example</h1>
<div class="column">
<ul>
<li>For 4 MPI processes</li>
</ul>
<div class="sourceCode" id="cb4"><pre class="sourceCode fortran"><code class="sourceCode fortran"><a class="sourceLine" id="cb4-1" title="1"><span class="kw">IF</span> (rank<span class="op">==</span><span class="dv">0</span>) <span class="kw">THEN</span></a>
<a class="sourceLine" id="cb4-2" title="2">    <span class="kw">DO</span> i <span class="kw">=</span> <span class="dv">1</span>, <span class="dv">16</span></a>
<a class="sourceLine" id="cb4-3" title="3">        a(i) <span class="kw">=</span> i</a>
<a class="sourceLine" id="cb4-4" title="4">    <span class="kw">END DO</span></a>
<a class="sourceLine" id="cb4-5" title="5"><span class="kw">END IF</span></a>
<a class="sourceLine" id="cb4-6" title="6"><span class="kw">CALL</span> MPI_Scatter(a, <span class="dv">4</span>, MPI_<span class="dt">INTEGER</span>, aloc, <span class="dv">4</span> <span class="kw">&amp;</span></a>
<a class="sourceLine" id="cb4-7" title="7">              MPI_<span class="dt">INTEGER</span>, <span class="dv">0</span>, MPI_COMM_WORLD, <span class="kw">&amp;</span></a>
<a class="sourceLine" id="cb4-8" title="8">              err)</a>
<a class="sourceLine" id="cb4-9" title="9"><span class="kw">IF</span> (rank<span class="op">==</span><span class="dv">2</span>) <span class="fu">WRITE(*</span>,<span class="fu">*)</span> aloc(:)</a></code></pre></div>
</div>
<div class=column>
<p>What would be the result?</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb5-1" title="1"><span class="ex">9</span> 10 11 12</a></code></pre></div>
<p>→ Rank 0 consecutively sends blocks of 4 elements from an array of length 16 to other ranks, i.e. rank 0 gets numbers 1-4, rank 1 gets 5-8 etc.</p>
<div>
</section>
<section id="mpi_gather" class="slide level1 split-definition" data-background-size="contain">
<h1><strong><code>MPI_Gather</code></strong></h1>
<ul>
<li>Collect data from other processes to a root - “inverse” scatter</li>
</ul>
<p><img data-src="img/gather.svg" class="center" style="width:55.0%" /></p>
</section>
<section id="mpi_gather-1" class="slide level1 split-definition" data-background-size="contain">
<h1><strong><code>MPI_Gather</code></strong></h1>
<dl>
<dt>MPI_Gather(<code class="input">sendbuf</code>, <code class="input">sendcount</code>, <code class="input">sendtype</code>, <code class="output">recvbuf</code>,<code class="input">recvcount</code>, <code class="input">recvtype</code>, <code class="input">root</code>, <code class="input">comm</code>, <code class="output">err</code>)</dt>
<dd><dl>
<dt>type(*) <code class="input">sendbuf(..)</code></dt>
<dd>Data to be gathered
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">sendcount</code></dt>
<dd>Number of elements sent by each process
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">sendtype</code></dt>
<dd>Type of elements sent
</dd>
</dl>
</dd>
<dd><dl>
<dt>type(*) <code class="output">recvbuf(..)</code></dt>
<dd>Buffer for receiving data
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">recvcount</code></dt>
<dd>Number of elements to receive
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">recvtype</code></dt>
<dd>Type of elements to receive
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">root</code></dt>
<dd>The rank of receiving process
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">comm</code></dt>
<dd>Communicator
</dd>
</dl>
</dd>
</dl>
</section>
<section id="mpi_reduce" class="slide level1 split-definition" data-background-size="contain">
<h1><strong><code>MPI_Reduce</code></strong></h1>
<ul>
<li>Apply a reduction operation across processes and place the result in a specified root process</li>
</ul>
<dl>
<dt>MPI_Reduce(<code class="input">sendbuf</code>, <code class="output">recvbuf</code>, <code class="input">count</code>, <code class="input">datatype</code>, <code class="input">op</code>, <code class="input">root</code>, <code class="input">comm</code>, <code class="output">err</code>)</dt>
<dd><dl>
<dt>type(*) <code class="input">sendbuf(..)</code></dt>
<dd>Data to be reduced
</dd>
</dl>
</dd>
<dd><dl>
<dt>type(*) <code class="output">recvbuf(..)</code></dt>
<dd>Buffer for receiving data
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">count</code></dt>
<dd>Number of elements in send buffer
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">datatype</code></dt>
<dd>Type of elements in send buffer
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">op</code></dt>
<dd>Applied operation
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">root</code></dt>
<dd>The rank of receiving process
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">comm</code></dt>
<dd>Communicator
</dd>
</dl>
</dd>
</dl>
</section>
<section id="mpi_reduce-1" class="slide level1 split-definition" data-background-size="contain">
<h1><strong><code>MPI_Reduce</code></strong></h1>
<ul>
<li>Several different operations available</li>
</ul>
<div class="column">
<table>
<thead>
<tr class="header">
<th>Operation</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>MPI_MAX</code></td>
<td>Max value</td>
</tr>
<tr class="even">
<td><code>MPI_MIN</code></td>
<td>Min value</td>
</tr>
<tr class="odd">
<td><code>MPI_SUM</code></td>
<td>Sum</td>
</tr>
<tr class="even">
<td><code>MPI_PROD</code></td>
<td>Product</td>
</tr>
<tr class="odd">
<td><code>MPI_MAXLOC</code></td>
<td>Max value + location</td>
</tr>
<tr class="even">
<td><code>MPI_MINLOC</code></td>
<td>Min value + location</td>
</tr>
</tbody>
</table>
</div>
<div class="column">
<table>
<thead>
<tr class="header">
<th>Operation</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>MPI_LAND</code></td>
<td>Logical AND</td>
</tr>
<tr class="even">
<td><code>MPI_BAND</code></td>
<td>Bitwise AND</td>
</tr>
<tr class="odd">
<td><code>MPI_LOR</code></td>
<td>Logical OR</td>
</tr>
<tr class="even">
<td><code>MPI_BOR</code></td>
<td>Bitwise OR</td>
</tr>
<tr class="odd">
<td><code>MPI_LXOR</code></td>
<td>Logical XOR</td>
</tr>
<tr class="even">
<td><code>MPI_BXOR</code></td>
<td>Bitwise XOR</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="example-parallel-dot-product" class="slide level1 split-definition" data-background-size="contain">
<h1>Example: parallel dot product</h1>
<div class="column">
<div class="sourceCode" id="cb6"><pre class="sourceCode fortran"><code class="sourceCode fortran"><a class="sourceLine" id="cb6-1" title="1"><span class="dt">REAL</span> <span class="dt">::</span> a(<span class="dv">1024</span>), aloc(<span class="dv">128</span>), r, rloc</a>
<a class="sourceLine" id="cb6-2" title="2">...</a>
<a class="sourceLine" id="cb6-3" title="3"><span class="kw">IF</span> (rank<span class="op">==</span><span class="dv">0</span>) <span class="kw">THEN</span></a>
<a class="sourceLine" id="cb6-4" title="4">    <span class="kw">CALL</span> <span class="fu">random_number</span>(a)</a>
<a class="sourceLine" id="cb6-5" title="5"><span class="kw">END IF</span></a>
<a class="sourceLine" id="cb6-6" title="6"><span class="kw">CALL</span> MPI_Scatter(a, <span class="dv">128</span>, MPI_<span class="dt">INTEGER</span>, <span class="kw">&amp;</span></a>
<a class="sourceLine" id="cb6-7" title="7">                 aloc, <span class="dv">128</span>, MPI_<span class="dt">INTEGER</span>, <span class="kw">&amp;</span></a>
<a class="sourceLine" id="cb6-8" title="8">                 <span class="dv">0</span>, MPI_COMM_WORLD, err)</a>
<a class="sourceLine" id="cb6-9" title="9">rloc <span class="kw">=</span> <span class="fu">SUM</span>(aloc(:)<span class="kw">**</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb6-10" title="10"><span class="kw">CALL</span> MPI_Reduce(rloc, r, <span class="dv">1</span>, MPI_REAL, <span class="kw">&amp;</span></a>
<a class="sourceLine" id="cb6-11" title="11">                MPI_SUM, <span class="dv">0</span>, MPI_COMM_WORLD, <span class="kw">&amp;</span></a>
<a class="sourceLine" id="cb6-12" title="12">                err)</a>
<a class="sourceLine" id="cb6-13" title="13"><span class="fu">WRITE(*</span>,<span class="fu">*)</span> <span class="st">&quot;id=&quot;</span>, rank, <span class="st">&quot; local=&quot;</span>rloc</a>
<a class="sourceLine" id="cb6-14" title="14"><span class="kw">IF</span> (rank<span class="op">==</span><span class="dv">0</span>) <span class="fu">WRITE(*</span>,<span class="fu">*)</span> <span class="st">&quot;global=&quot;</span>,r</a>
<a class="sourceLine" id="cb6-15" title="15"></a></code></pre></div>
</div>
<div class="column">
<ul>
<li>An array of random numbers is generated and distributed evenly across processes</li>
<li>Each process calculates the dot product of their portion of the array with itself, i.e. <span class="math inline">\(r_{loc} = a_{loc}(1)^2 + a_{loc}(2)^2 + ...\)</span></li>
<li>MPI reduction operator is used to sum up the final result across processes</li>
</ul>
</div>
</section>
<section id="example-parallel-dot-product-1" class="slide level1 split-definition" data-background-size="contain">
<h1>Example: parallel dot product</h1>
<div class="column">
<div class="sourceCode" id="cb7"><pre class="sourceCode fortran"><code class="sourceCode fortran"><a class="sourceLine" id="cb7-1" title="1"><span class="dt">REAL</span> <span class="dt">::</span> a(<span class="dv">1024</span>), aloc(<span class="dv">128</span>), r, rloc</a>
<a class="sourceLine" id="cb7-2" title="2">...</a>
<a class="sourceLine" id="cb7-3" title="3"><span class="kw">IF</span> (rank<span class="op">==</span><span class="dv">0</span>) <span class="kw">THEN</span></a>
<a class="sourceLine" id="cb7-4" title="4">    <span class="kw">CALL</span> <span class="fu">random_number</span>(a)</a>
<a class="sourceLine" id="cb7-5" title="5"><span class="kw">END IF</span></a>
<a class="sourceLine" id="cb7-6" title="6"><span class="kw">CALL</span> MPI_Scatter(a, <span class="dv">128</span>, MPI_<span class="dt">INTEGER</span>, <span class="kw">&amp;</span></a>
<a class="sourceLine" id="cb7-7" title="7">                 aloc, <span class="dv">128</span>, MPI_<span class="dt">INTEGER</span>, <span class="kw">&amp;</span></a>
<a class="sourceLine" id="cb7-8" title="8">                 <span class="dv">0</span>, MPI_COMM_WORLD, err)</a>
<a class="sourceLine" id="cb7-9" title="9">rloc <span class="kw">=</span> <span class="fu">SUM</span>(aloc(:)<span class="kw">**</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb7-10" title="10"><span class="kw">CALL</span> MPI_Reduce(rloc, r, <span class="dv">1</span>, MPI_REAL, <span class="kw">&amp;</span></a>
<a class="sourceLine" id="cb7-11" title="11">                MPI_SUM, <span class="dv">0</span>, MPI_COMM_WORLD, <span class="kw">&amp;</span></a>
<a class="sourceLine" id="cb7-12" title="12">                err)</a>
<a class="sourceLine" id="cb7-13" title="13"><span class="fu">WRITE(*</span>,<span class="fu">*)</span> <span class="st">&quot;id=&quot;</span>, rank, <span class="st">&quot; local=&quot;</span>rloc</a>
<a class="sourceLine" id="cb7-14" title="14"><span class="kw">IF</span> (rank<span class="op">==</span><span class="dv">0</span>) <span class="fu">WRITE(*</span>,<span class="fu">*)</span> <span class="st">&quot;global=&quot;</span>,r</a>
<a class="sourceLine" id="cb7-15" title="15"></a></code></pre></div>
</div>
<div class="column">
<div class="sourceCode" id="cb8"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb8-1" title="1"><span class="op">&gt;</span> <span class="ex">srun</span> -n 8 ./mpi_pdot</a>
<a class="sourceLine" id="cb8-2" title="2"> <span class="va">id=</span> <span class="ex">6</span> local= 39.68326</a>
<a class="sourceLine" id="cb8-3" title="3"> <span class="va">id=</span> <span class="ex">7</span> local= 39.34439</a>
<a class="sourceLine" id="cb8-4" title="4"> <span class="va">id=</span> <span class="ex">1</span> local= 42.86630</a>
<a class="sourceLine" id="cb8-5" title="5"> <span class="va">id=</span> <span class="ex">3</span> local= 44.16300</a>
<a class="sourceLine" id="cb8-6" title="6"> <span class="va">id=</span> <span class="ex">5</span> local= 39.76367</a>
<a class="sourceLine" id="cb8-7" title="7"> <span class="va">id=</span> <span class="ex">0</span> local= 42.85532</a>
<a class="sourceLine" id="cb8-8" title="8"> <span class="va">id=</span> <span class="ex">2</span> local= 40.67361</a>
<a class="sourceLine" id="cb8-9" title="9"> <span class="va">id=</span> <span class="ex">4</span> local= 49.45086</a>
<a class="sourceLine" id="cb8-10" title="10"> <span class="va">global=</span> <span class="ex">338.8004</span></a></code></pre></div>
</div>
</section>
<section id="mpi_alltoall" class="slide level1 split-definition" data-background-size="contain">
<h1><strong><code>MPI_Alltoall</code></strong></h1>
<ul>
<li>Spread data from each process to all processes</li>
<li>Resembles a transpose operation</li>
</ul>
<p><img data-src="img/alltoall.svg" class="center" style="width:65.0%" /></p>
</section>
<section id="mpi_alltoall-1" class="slide level1 split-definition" data-background-size="contain">
<h1><strong><code>MPI_Alltoall</code></strong></h1>
<dl>
<dt>MPI_Alltoall(<code class="input">sendbuf</code>, <code class="input">sendcount</code>, <code class="input">sendtype</code>, <code class="output">recvbuf</code>,<code class="input">recvcount</code>,<code class="input">recvtype</code>, <code class="input">comm</code>, <code class="output">err</code>)</dt>
<dd><dl>
<dt>type(*) <code class="input">sendbuf(..)</code></dt>
<dd>Data to be sent
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">sendcount</code></dt>
<dd>Number of elements to send by each process
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">sendtype</code></dt>
<dd>Type of elements to send
</dd>
</dl>
</dd>
<dd><dl>
<dt>type(*) <code class="output">recvbuf(..)</code></dt>
<dd>Buffer for receiving data
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">recvcount</code></dt>
<dd>Number of elements to receive from each process
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">recvtype</code></dt>
<dd>Type of elements to receive
</dd>
</dl>
</dd>
<dd><dl>
<dt>integer <code class="input">comm</code></dt>
<dd>Communicator
</dd>
</dl>
</dd>
</dl>
</section>
<section id="further-reading" class="slide level1" data-background-size="contain">
<h1>Further reading</h1>
<ul>
<li>The collective communication functions presented are blocking - non-blocking counterparts exist</li>
<li>Many also have other alternative/“extended” versions, e.g.
<ul>
<li><strong><code>MPI_Allreduce</code></strong>, <strong><code>MPI_Allgather</code></strong> – post the result to all processes</li>
<li><strong><code>MPI_Scatterv</code></strong>, <strong><code>MPI_Gatherv</code></strong> – scatter/gather with variable <strong><code class="input">sendcount</code></strong> across processes</li>
</ul></li>
</ul>
</section>
<section id="summary" class="slide level1" data-background-size="contain">
<h1>Summary</h1>
<ul>
<li><p>Non-blocking send/receive provide potential performance gains or may help resolving deadlocks</p>
<ul>
<li>Programmer must ensure successful data transfer</li>
</ul></li>
<li><p>Collective communication calls for a more efficient data exchange between several processes</p></li>
<li><p>Collective reduction operations enable straightforward arithmetics in parallelized datasets</p></li>
</ul>
</section>
    </div>
  </div>

  <script src="/home/jtonttil/SOFTWARE/slidefactory/lib/slidefactory/reveal.js/lib/js/head.min.js"></script>
  <script src="/home/jtonttil/SOFTWARE/slidefactory/lib/slidefactory/reveal.js/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Display controls in the bottom right corner
        controls: false,
        // Push each slide change to the browser history
        history: true,
        // Vertical centering of slides
        center: false,
        // Transition style
        transition: 'none', // none/fade/slide/convex/concave/zoom
        // Transition style for full page slide backgrounds
        backgroundTransition: 'none', // none/fade/slide/convex/concave/zoom
        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1920,
        height: 1080,
        math: {
          mathjax: '/home/jtonttil/SOFTWARE/slidefactory/lib/slidefactory/mathjax/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // Optional reveal.js plugins
        dependencies: [
          { src: '/home/jtonttil/SOFTWARE/slidefactory/lib/slidefactory/reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: '/home/jtonttil/SOFTWARE/slidefactory/lib/slidefactory/reveal.js/plugin/zoom-js/zoom.js', async: true },
          { src: '/home/jtonttil/SOFTWARE/slidefactory/lib/slidefactory/reveal.js/plugin/math/math.js', async: true },
          { src: '/home/jtonttil/SOFTWARE/slidefactory/lib/slidefactory/reveal.js/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
